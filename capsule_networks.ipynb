{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash(inputs, epsilon):\n",
    "    with tf.name_scope('squash'):\n",
    "        input_squared_norm = tf.reduce_sum(tf.square(inputs), -2, keep_dims=True, name='squared_norm')\n",
    "        scalar_factor = input_squared_norm / (1 + input_squared_norm) \n",
    "        scalar_factor = scalar_factor / tf.sqrt(input_squared_norm + epsilon)\n",
    "        squashed_input = tf.multiply(scalar_factor, inputs, name='squashed_output')\n",
    "    return squashed_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_capsule(inputs, batch_size, outputs, vector_length, strides, num_kernels, epsilon):\n",
    "    capsules = tf.contrib.layers.conv2d(inputs,  outputs * vector_length, num_kernels, strides, padding=\"VALID\", activation_fn=tf.nn.relu)\n",
    "    capsules = tf.reshape(capsules, [-1, 1152, vector_length, 1], name='capsules_reshape')\n",
    "    capsules = squash(capsules, epsilon)\n",
    "    assert(capsules.get_shape()[1:] == [1152, 8 , 1])\n",
    "    print('Primary Capsule Shape '+str(capsules.get_shape()))\n",
    "    return capsules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(name, stddev, shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape=shape, stddev=stddev), name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_fc(inputs, batch_size, outputs, stddev, routing_iters, epsilon):\n",
    "    inputs = tf.reshape(inputs, [-1, 1152, 1, inputs.shape[-2].value, 1])\n",
    "    inputs_shape = inputs.get_shape()\n",
    "    print(inputs_shape)\n",
    "    b_ij = tf.constant(np.zeros([batch_size, inputs.shape[1].value, outputs, 1, 1], dtype=np.float32), name='b_ij')\n",
    "#     b_ij = tf.zeros([batch_size, inputs.shape[1].value, outputs, 1, 1], dtype=np.float32), name='b_ij')\n",
    "    W = get_weights('Weight', shape=(1, 1152, 10, 8, 16), stddev=stddev)\n",
    "\n",
    "    inputs = tf.tile(inputs, [1, 1, 10, 1, 1])\n",
    "    W = tf.tile(W, [batch_size, 1, 1, 1, 1])\n",
    "    assert(inputs.get_shape()[1:] == [1152, 10, 8, 1])\n",
    "    \n",
    "    u_cap = tf.matmul(W, inputs, transpose_a=True)\n",
    "    assert(u_cap.get_shape()[1:] == [1152, 10, 16, 1])\n",
    "\n",
    "    u_cap_not_passed = tf.stop_gradient(u_cap, name='stop_gradient')\n",
    "\n",
    "    for iter_i in range(routing_iters):\n",
    "        with tf.variable_scope('iter_' + str(iter_i)):\n",
    "            c_ij = tf.nn.softmax(b_ij, dim=2)\n",
    "            \n",
    "            if iter_i == routing_iters - 1:\n",
    "                s_j = tf.multiply(c_ij, u_cap)\n",
    "                s_j = tf.reduce_sum(s_j, axis=1, keep_dims=True)\n",
    "                assert(s_j.get_shape()[1:] == [1, 10, 16, 1])\n",
    "                v_j = squash(s_j, epsilon)\n",
    "                assert(v_j.get_shape()[1:] == [1, 10, 16, 1])\n",
    "            \n",
    "            elif iter_i < routing_iters - 1:\n",
    "                s_j = tf.multiply(c_ij, u_cap_not_passed)\n",
    "                s_j = tf.reduce_sum(s_j, axis=1, keep_dims=True)\n",
    "                v_j = squash(s_j, epsilon)\n",
    "                v_j_replica = tf.tile(v_j, [1, 1152, 1, 1, 1])\n",
    "                u_v = tf.matmul(u_cap_not_passed, v_j_replica, transpose_a=True)\n",
    "                assert(u_v.get_shape() == b_ij.get_shape())\n",
    "                b_ij += u_v\n",
    "    \n",
    "    print('Digit Caps Shape '+str(v_j.get_shape()))\n",
    "    return v_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(batch_size, epsilon):\n",
    "    with tf.name_scope('inputs'):\n",
    "        x_i = tf.placeholder(tf.float32, shape=[None, 784], name = 'x')\n",
    "        y = tf.placeholder(tf.float32, shape=[None, 10], name = 'y')\n",
    "        \n",
    "    with tf.name_scope('reshape_input'):\n",
    "        x = tf.reshape(x_i, [-1,28,28,1], name='reshape_x')\n",
    "    \n",
    "    with tf.name_scope('ReLUConv1'):\n",
    "        conv1 = tf.nn.relu(tf.contrib.layers.conv2d(x, num_outputs=256, kernel_size=9, stride=1, padding='VALID'), name = 'ReLUConv1')\n",
    "        print('Conv1 Shape: '+str(conv1.get_shape()))\n",
    "        assert(conv1.get_shape()[1:] == [20, 20, 256])\n",
    "\n",
    "    with tf.name_scope('PrimaryCaps'):\n",
    "        primary_caps = add_capsule(conv1, batch_size = batch_size, outputs=32, vector_length=8, strides=2, num_kernels=9, epsilon=epsilon)\n",
    "        assert(primary_caps.get_shape()[1:] == [1152, 8, 1])\n",
    "\n",
    "    with tf.name_scope('DigitCaps'):\n",
    "        digit_caps = add_fc(primary_caps, batch_size = batch_size, outputs=10, stddev = 0.01, routing_iters= 3, epsilon = epsilon)\n",
    "        digit_caps = tf.reshape(digit_caps, [-1, 10, 16, 1])\n",
    "        print('Reshaped Digit Caps: '+str(digit_caps.get_shape()))\n",
    "        assert(digit_caps.get_shape()[1:] == [10, 16, 1])\n",
    "        \n",
    "    return x_i, y, digit_caps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_data, batch_size, iters, m_plus, m_minus, lambda_val):\n",
    "    epsilon = 1e-9\n",
    "    x, y, digit_caps = get_model(batch_size, epsilon)\n",
    "    with tf.name_scope('output'):\n",
    "        v_l2 = tf.sqrt(tf.reduce_sum(tf.square(digit_caps), axis=2, keep_dims=True) + epsilon, name='output')\n",
    "        print('v_l2 shape: '+str(v_l2.get_shape()))\n",
    "        softmax_v =tf.reshape(tf.nn.softmax(v_l2, dim=1), [-1, 10], name='softmax_output')\n",
    "        print('Softmax shape: '+str(softmax_v.get_shape()))\n",
    "        assert(softmax_v.get_shape() == [batch_size, 10])\n",
    "        \n",
    "    with tf.name_scope('loss'):\n",
    "        v_l = tf.reshape(v_l2, [-1, 10])\n",
    "        lc = y * tf.square(tf.maximum(0.0, m_plus - v_l)) + lambda_val * (1 - y) * tf.square(tf.maximum(0.0, v_l - m_minus))\n",
    "        loss = tf.reduce_mean(tf.reduce_sum(lc, axis= 1), name='loss')\n",
    "    \n",
    "    with tf.name_scope('train'):\n",
    "        train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "        tf.summary.scalar('loss', loss)\n",
    "        \n",
    "    with tf.name_scope('accuracy'):\n",
    "        correct_prediction = tf.equal(tf.argmax(softmax_v, 1), tf.argmax(y, 1))\n",
    "        correct_prediction = tf.cast(correct_prediction, tf.float32)\n",
    "        accuracy = tf.reduce_mean(correct_prediction, name = 'accuracy')\n",
    "        tf.summary.scalar('accuracy', accuracy)\n",
    "    \n",
    "    summ = tf.summary.merge_all()\n",
    "    \n",
    "    builder = tf.saved_model.builder.SavedModelBuilder('models/')\n",
    "    writer = tf.summary.FileWriter('logs_output_1')\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        writer.add_graph(sess.graph)\n",
    "        for i in range(iters):\n",
    "            batch = train_data.next_batch(batch_size)\n",
    "            sess.run([train_step], feed_dict={x:batch[0], y:batch[1]})\n",
    "            if i%10 == 0:\n",
    "                acc, s = sess.run([accuracy, summ],feed_dict={x:batch[0], y:batch[1]})\n",
    "                print(\"Accuracy after \"+str(i)+\" iterations is \"+str(acc))\n",
    "                writer.add_summary(s, i)\n",
    "        builder.add_meta_graph_and_variables(sess,['model_'+str(iters)+'iters'])\n",
    "        builder.save()\n",
    "        writer.close()\n",
    "        print(\"Complete!\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_data, iters, batch_size):\n",
    "    tf.reset_default_graph()\n",
    "    with tf.Session() as sess:\n",
    "        tf.saved_model.loader.load(sess,['model_'+str(iters)+'iters'],'models/')\n",
    "        test_len = len(test_data.images) // batch_size\n",
    "        mean_acc = 0.0\n",
    "        for i in range(test_len):\n",
    "            acc = sess.run(['accuracy/accuracy:0'], feed_dict={'inputs/x:0':test_data.images[i*128:(i+1)*128], 'inputs/y:0':test_data.labels[i*128:(i+1)*128]})[0]\n",
    "            print('Accuracy in iter '+str(i)+' is '+str(acc))\n",
    "            mean_acc += acc\n",
    "        print(\"Test Accuracy is \"+str(mean_acc/test_len))    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    epochs = 10\n",
    "    batch_size = 128\n",
    "    m_plus = 0.9\n",
    "    m_minus = 0.1\n",
    "    lambda_val = 0.5\n",
    "    \n",
    "    if not tf.gfile.Exists('dataset/'):\n",
    "        print('creating dataset dir')\n",
    "        tf.gfile.MakeDirs('dataset')\n",
    "    print('Loading dataset')\n",
    "    mnist = input_data.read_data_sets('dataset/', one_hot=True)\n",
    "    iters = 10*len(mnist.train.images) // batch_size\n",
    "    print('Loading Complete')\n",
    "    print('Will be running for '+str(iters)+' iters')\n",
    "    if tf.gfile.Exists('models/'):\n",
    "        flag = input('Do you want to reset the model and train: ')\n",
    "        if flag == 'y' or flag == 'Y':\n",
    "            tf.gfile.DeleteRecursively('models/')\n",
    "            train(mnist.train, batch_size, iters, m_plus, m_minus, lambda_val)\n",
    "    else:\n",
    "        train(mnist.train, batch_size, iters, m_plus, m_minus, lambda_val)\n",
    "    \n",
    "    test(mnist.test, iters, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset\n",
      "Extracting dataset/train-images-idx3-ubyte.gz\n",
      "Extracting dataset/train-labels-idx1-ubyte.gz\n",
      "Extracting dataset/t10k-images-idx3-ubyte.gz\n",
      "Extracting dataset/t10k-labels-idx1-ubyte.gz\n",
      "Loading Complete\n",
      "Will be running for 4296 iters\n",
      "Do you want to reset the model and train: n\n",
      "INFO:tensorflow:Restoring parameters from b'models/variables/variables'\n",
      "Accuracy in iter 0 is 1.0\n",
      "Accuracy in iter 1 is 0.992188\n",
      "Accuracy in iter 2 is 0.976562\n",
      "Accuracy in iter 3 is 0.984375\n",
      "Accuracy in iter 4 is 0.992188\n",
      "Accuracy in iter 5 is 0.960938\n",
      "Accuracy in iter 6 is 1.0\n",
      "Accuracy in iter 7 is 0.984375\n",
      "Accuracy in iter 8 is 0.984375\n",
      "Accuracy in iter 9 is 0.976562\n",
      "Accuracy in iter 10 is 0.984375\n",
      "Accuracy in iter 11 is 0.976562\n",
      "Accuracy in iter 12 is 0.992188\n",
      "Accuracy in iter 13 is 0.984375\n",
      "Accuracy in iter 14 is 0.976562\n",
      "Accuracy in iter 15 is 0.984375\n",
      "Accuracy in iter 16 is 0.976562\n",
      "Accuracy in iter 17 is 0.992188\n",
      "Accuracy in iter 18 is 0.992188\n",
      "Accuracy in iter 19 is 0.992188\n",
      "Accuracy in iter 20 is 0.984375\n",
      "Accuracy in iter 21 is 1.0\n",
      "Accuracy in iter 22 is 0.984375\n",
      "Accuracy in iter 23 is 1.0\n",
      "Accuracy in iter 24 is 0.992188\n",
      "Accuracy in iter 25 is 1.0\n",
      "Accuracy in iter 26 is 0.992188\n",
      "Accuracy in iter 27 is 0.976562\n",
      "Accuracy in iter 28 is 1.0\n",
      "Accuracy in iter 29 is 0.96875\n",
      "Accuracy in iter 30 is 0.96875\n",
      "Accuracy in iter 31 is 0.992188\n",
      "Accuracy in iter 32 is 0.976562\n",
      "Accuracy in iter 33 is 0.984375\n",
      "Accuracy in iter 34 is 1.0\n",
      "Accuracy in iter 35 is 0.992188\n",
      "Accuracy in iter 36 is 1.0\n",
      "Accuracy in iter 37 is 0.976562\n",
      "Accuracy in iter 38 is 0.984375\n",
      "Accuracy in iter 39 is 1.0\n",
      "Accuracy in iter 40 is 1.0\n",
      "Accuracy in iter 41 is 1.0\n",
      "Accuracy in iter 42 is 1.0\n",
      "Accuracy in iter 43 is 1.0\n",
      "Accuracy in iter 44 is 0.984375\n",
      "Accuracy in iter 45 is 1.0\n",
      "Accuracy in iter 46 is 0.984375\n",
      "Accuracy in iter 47 is 1.0\n",
      "Accuracy in iter 48 is 1.0\n",
      "Accuracy in iter 49 is 1.0\n",
      "Accuracy in iter 50 is 0.992188\n",
      "Accuracy in iter 51 is 0.96875\n",
      "Accuracy in iter 52 is 0.992188\n",
      "Accuracy in iter 53 is 1.0\n",
      "Accuracy in iter 54 is 1.0\n",
      "Accuracy in iter 55 is 1.0\n",
      "Accuracy in iter 56 is 1.0\n",
      "Accuracy in iter 57 is 1.0\n",
      "Accuracy in iter 58 is 0.992188\n",
      "Accuracy in iter 59 is 1.0\n",
      "Accuracy in iter 60 is 1.0\n",
      "Accuracy in iter 61 is 1.0\n",
      "Accuracy in iter 62 is 1.0\n",
      "Accuracy in iter 63 is 0.992188\n",
      "Accuracy in iter 64 is 1.0\n",
      "Accuracy in iter 65 is 0.992188\n",
      "Accuracy in iter 66 is 0.992188\n",
      "Accuracy in iter 67 is 1.0\n",
      "Accuracy in iter 68 is 1.0\n",
      "Accuracy in iter 69 is 1.0\n",
      "Accuracy in iter 70 is 0.992188\n",
      "Accuracy in iter 71 is 1.0\n",
      "Accuracy in iter 72 is 1.0\n",
      "Accuracy in iter 73 is 1.0\n",
      "Accuracy in iter 74 is 1.0\n",
      "Accuracy in iter 75 is 0.976562\n",
      "Accuracy in iter 76 is 0.976562\n",
      "Accuracy in iter 77 is 0.992188\n",
      "Test Accuracy is 0.991085737179\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
